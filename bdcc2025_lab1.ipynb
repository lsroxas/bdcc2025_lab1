{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586b0510-782f-4926-a89c-b5fb910af28e",
   "metadata": {},
   "source": [
    "# Analyzing OSS Projects under the Apache Software Foundation using GH Archive Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b834c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Apache Software Foundation (ASF) is a non-profit organization that supports various open-source software projects. The ASF has a large number of projects, and understanding the activity and trends within these projects can provide valuable insights into the open-source ecosystem.\n",
    "This analysis aims to explore the activity of Apache projects using data from the GitHub Archive (GH Archive). The GH Archive provides a record of public GitHub events, which can be used to analyze the activity of repositories over time since 2011. The dataset encompasses bullions of events like commits, issues, pull requests, and more. this dataset precents an opportunity for large-sclae analysis of open-source projects. \n",
    "\n",
    "This report's objectives are:\n",
    "* To identify key activity metrics derivable from the GH Archite dataset. \n",
    "* Provide descriptive analytics on these metrics over time for a selection of projects under ASF.\n",
    "* Describe the patterns and trends associated with the different phases of an open-source project's lifecycle.\n",
    "* Develop data-informed heuristics suggesting optimal project adoption and migration points. \n",
    "\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "### BigQuery Extract\n",
    "The data for this analysis was collected from the GH Archive. A copy updated daily copy of this dataset is available on Google BigQuery under the `gharchive` public dataset. The data set was extracted using the following SQL query:\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM `githubarchive.year.202*`\n",
    "WHERE \n",
    "repo.name like 'apache/%'\n",
    "```\n",
    "Screenshot of the export jobs is seen below:\n",
    "\n",
    "![Export Job](./images/bigquery_export_job.png)\n",
    "\n",
    "The results of the query was exported as parquet files on a Google Cloud Storage bucket and copied over the the `/home/ubuntu/lab1/data` folder of the EC2 instance used by the project. \n",
    "\n",
    "### Partitioning the Data prior to Analysis\n",
    "The exported parquet are then accessed using Apache Spark. A copy of the data files partitioned by project name is then create and saved under `/home/ubuntu/lab1/partitioned_data` folder. The data is partitioned by project name to allow for easier access and analysis on a per project basis. The data is also partitioned by year, month, and day to allow for easier access and analysis of individual years. The data is then saved as parquet files in the `partitioned_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985bcbf-40d5-4b18-abeb-14c6d2ef1983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22G\t./data\n"
     ]
    }
   ],
   "source": [
    "!du -sh ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23a7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
